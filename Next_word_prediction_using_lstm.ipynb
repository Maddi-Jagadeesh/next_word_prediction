{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MrNf1lh-15AQ"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"Artificial intelligence is transforming the world at an unprecedented pace, revolutionizing industries and reshaping the way humans interact with technology.\n",
        "From healthcare to finance, AI-powered systems are improving efficiency, accuracy, and decision-making.\n",
        "In healthcare, AI assists in diagnosing diseases, predicting patient outcomes, and personalizing treatments based on vast amounts of data.\n",
        "Medical imaging powered by deep learning can detect anomalies such as tumors or fractures with higher precision than human radiologists.\n",
        "AI-driven robotic surgeries enhance precision and reduce risks, improving patient recovery times.\n",
        "In finance, algorithms analyze market trends, detect fraudulent transactions, and automate trading strategies.\n",
        "The rise of machine learning and deep learning has enabled computers to learn from data and make predictions without explicit programming.\n",
        "Banks and financial institutions use AI to assess creditworthiness, manage risks, and provide personalized financial recommendations.\n",
        "In the realm of communication, natural language processing allows AI models to understand and generate human-like text, revolutionizing customer service with chatbots and virtual assistants.\n",
        "AI-driven translation services break language barriers, enabling global connectivity.\n",
        "Social media platforms leverage AI for content moderation, detecting harmful speech, and curating personalized content for users.\n",
        "E-commerce platforms use AI-powered recommendation engines to suggest products based on user behavior, enhancing shopping experiences and boosting sales.\n",
        "In transportation, autonomous vehicles leverage AI to navigate roads, interpret traffic signals, and enhance safety through real-time decision-making.\n",
        "AI-powered traffic management systems optimize road conditions by predicting congestion patterns and adjusting signals accordingly.\n",
        "Education is also undergoing a transformation with AI-driven learning platforms that provide personalized tutoring, automate grading, and analyze student progress to offer targeted learning resources.\n",
        "AI can identify struggling students and suggest interventions to improve learning outcomes.\n",
        "In entertainment, AI is used for content generation, music composition, and video editing.\n",
        "Streaming services analyze user preferences to recommend movies, TV shows, and music.\n",
        "AI-generated art and literature challenge traditional notions of creativity and human expression.\n",
        "While AI offers numerous benefits, ethical concerns arise regarding job displacement, privacy, and bias in decision-making algorithms.\n",
        "Automation threatens to replace human workers in industries such as manufacturing, logistics, and customer service, raising questions about workforce reskilling and economic inequality.\n",
        "AI systems trained on biased datasets may produce unfair outcomes, perpetuating discrimination in areas such as hiring, lending, and law enforcement.\n",
        "The development of explainable AI is crucial to ensure transparency and fairness in automated systems.\n",
        "Researchers are working on methods to make AI decisions more interpretable, reducing the black-box nature of deep learning models.\n",
        "Governments and organizations are working to establish regulations that balance innovation with accountability, ensuring AI is used ethically and responsibly.\n",
        "As AI continues to evolve, its integration into daily life will expand, influencing education, entertainment, and scientific research.\n",
        "AI is being used to accelerate discoveries in fields such as drug development, climate modeling, and space exploration.\n",
        "Scientists use AI to analyze complex genetic data, leading to breakthroughs in precision medicine and personalized therapies.\n",
        "In climate science, AI helps model and predict climate change effects, guiding policy decisions for sustainability.\n",
        "The use of AI in robotics is enabling the creation of humanoid robots that can perform tasks ranging from elderly care to industrial automation.\n",
        "The future of AI depends on responsible development and collaboration between technologists, policymakers, and society.\n",
        "While AI presents unprecedented opportunities, ensuring its ethical use requires ongoing discussion, regulation, and adaptation.\n",
        "By leveraging AI responsibly, humanity can unlock its full potential while mitigating risks and ensuring a future where technology serves all of society.\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "T=Tokenizer()\n",
        "T.fit_on_texts([text])\n"
      ],
      "metadata": {
        "id": "xvJJCkyv2ZYl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(T.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcaDKZge2iZu",
        "outputId": "3de54226-ccbe-43f3-cde2-dba4c504ba2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "346"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=[]\n",
        "for sentence in text.split('.'):\n",
        "  token=T.texts_to_sequences([sentence])\n",
        "  for i in range(1,len(token[0])):\n",
        "    inputs.append((token[0][:i+1]))"
      ],
      "metadata": {
        "id": "pZGbJ7HJ2vtU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in inputs])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgf9vbth3Pf4",
        "outputId": "19706e7a-2ab3-42dc-e009-8c8099e2a4c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input=pad_sequences(inputs,maxlen=max_len,padding='pre')\n"
      ],
      "metadata": {
        "id": "Tkwtv9R44qAe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbt2kOGO5AbN",
        "outputId": "d82b8401-531d-4609-9284-593b5f4bec43"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=padded_input[:,:-1]\n",
        "y=padded_input[:,-1]"
      ],
      "metadata": {
        "id": "AN-KaElu5CN5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7a21pPX5ntF",
        "outputId": "4e7bb2dc-1a5c-4e8a-ec9f-eb0d61aad2f6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(552, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHzxcZ_y5pPJ",
        "outputId": "7b50951e-32d7-487b-ac3f-8dbcd0134b55"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(552,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(T.word_index)+1)"
      ],
      "metadata": {
        "id": "qKn1kSRQ5rhA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,LSTM,Dropout\n"
      ],
      "metadata": {
        "id": "ufP3O_Ui54_m"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=len(T.word_index)+1, output_dim=100, input_length=26 - 1))\n",
        "model.build((None,26-1)) # build the Embedding to inilizices the weight\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(len(T.word_index)+1,activation='softmax'))"
      ],
      "metadata": {
        "id": "kDm7Tird6G5j"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VIYPvuXE6mnC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "hKeYebXQ6rIl",
        "outputId": "81505bfd-962b-4186-9971-86fd755d7da7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m34,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m100,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m347\u001b[0m)                 │          \u001b[38;5;34m35,047\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">347</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">35,047</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,747\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,747</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,747\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,747</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h=model.fit(x,y,epochs=100,verbose=0)"
      ],
      "metadata": {
        "id": "duRRf6Vu8Fa8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vu3qBjXV-NZx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test1=\"The combination of deep learning and reinforcement learning\"\n",
        "for i in range(10):\n",
        "  tokenized_text=T.texts_to_sequences([test1])\n",
        "  padded_text=pad_sequences(tokenized_text,maxlen=25,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_text))\n",
        "  for word,index in T.word_index.items():\n",
        "    if (index==pos):\n",
        "      test1=test1+\" \"+word\n",
        "      print(test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVIP4uAq9tLS",
        "outputId": "e7ed6fa5-04c7-4bc3-ef51-1fdf803eb7e0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "The combination of deep learning and reinforcement learning learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing logistics\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing logistics and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing logistics and learn\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing logistics and learn from\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "The combination of deep learning and reinforcement learning learning learning as as manufacturing logistics and learn from data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1=\"Artificial intelligence is transforming the way\"\n",
        "for i in range(10):\n",
        "  tokenized_text=T.texts_to_sequences([test1])\n",
        "  padded_text=pad_sequences(tokenized_text,maxlen=25,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_text))\n",
        "  for word,index in T.word_index.items():\n",
        "    if (index==pos):\n",
        "      test1=test1+\" \"+word\n",
        "      print(test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SagsgREZ-kMI",
        "outputId": "3208636d-3965-4a67-a954-91956a0f77be"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Artificial intelligence is transforming the way at\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Artificial intelligence is transforming the way at an\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing industries\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing industries and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing industries and reshaping\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing industries and reshaping the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Artificial intelligence is transforming the way at an unprecedented pace revolutionizing industries and reshaping the way\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = \"Machine learning algorithms are designed to\"\n",
        "for i in range(10):\n",
        "  tokenized_text=T.texts_to_sequences([test1])\n",
        "  padded_text=pad_sequences(tokenized_text,maxlen=25,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_text))\n",
        "  for word,index in T.word_index.items():\n",
        "    if (index==pos):\n",
        "      test1=test1+\" \"+word\n",
        "      print(test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haGyA4kKAbZT",
        "outputId": "696edd3b-2589-4ef2-d02e-88efdf7754b6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Machine learning algorithms are designed to model\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Machine learning algorithms are designed to model and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Machine learning algorithms are designed to model and predict\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Machine learning algorithms are designed to model and predict climate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change effects\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change effects policy\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change effects policy decisions\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change effects policy decisions for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Machine learning algorithms are designed to model and predict climate change effects policy decisions for sustainability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test1 = \"Deep learning models such as convolutional neural networks\"\n",
        "for i in range(10):\n",
        "  tokenized_text=T.texts_to_sequences([test1])\n",
        "  padded_text=pad_sequences(tokenized_text,maxlen=25,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_text))\n",
        "  for word,index in T.word_index.items():\n",
        "    if (index==pos):\n",
        "      test1=test1+\" \"+word\n",
        "      print(test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HKphABBAoUy",
        "outputId": "5567bfd2-ec93-40b2-a54c-ec16a84f381b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Deep learning models such as convolutional neural networks in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest products\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest products based\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest products based on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest products based on user\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Deep learning models such as convolutional neural networks in recommendation engines and suggest products based on user shopping\n"
          ]
        }
      ]
    }
  ]
}